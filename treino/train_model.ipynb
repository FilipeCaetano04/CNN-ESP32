{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e910a6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b8bf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36576 files belonging to 36 classes.\n",
      "Using 29261 files for training.\n",
      "Found 36576 files belonging to 36 classes.\n",
      "Using 7315 files for validation.\n",
      "Classes encontradas: ['Sample001', 'Sample002', 'Sample003', 'Sample004', 'Sample005', 'Sample006', 'Sample007', 'Sample008', 'Sample009', 'Sample010', 'Sample011', 'Sample012', 'Sample013', 'Sample014', 'Sample015', 'Sample016', 'Sample017', 'Sample018', 'Sample019', 'Sample020', 'Sample021', 'Sample022', 'Sample023', 'Sample024', 'Sample025', 'Sample026', 'Sample027', 'Sample028', 'Sample029', 'Sample030', 'Sample031', 'Sample032', 'Sample033', 'Sample034', 'Sample035', 'Sample036']\n",
      "Total de classes: 36\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "IMG_SIZE = 64     \n",
    "CHANNELS = 1       \n",
    "BATCH_SIZE = 32   \n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    r'C:\\Users\\paulo\\OneDrive\\Área de Trabalho\\PDI_CNN\\placas',\n",
    "    validation_split=0.2, \n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    r'C:\\Users\\paulo\\OneDrive\\Área de Trabalho\\PDI_CNN\\placas',\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "print(f\"Classes encontradas: {train_ds.class_names}\")\n",
    "print(f\"Total de classes: {len(train_ds.class_names)}\")\n",
    "\n",
    "normalization_layer = layers.Rescaling(1./127.5, offset=-1)\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5863a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\paulo\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\paulo\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\backend.py:1400: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\paulo\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\optimizers\\__init__.py:317: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Iniciando Treinamento com QAT...\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:From C:\\Users\\paulo\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\paulo\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "915/915 [==============================] - 60s 63ms/step - loss: 3.4610 - accuracy: 0.0556 - val_loss: 3.0677 - val_accuracy: 0.1610\n",
      "Epoch 2/15\n",
      "915/915 [==============================] - 25s 27ms/step - loss: 2.8661 - accuracy: 0.1908 - val_loss: 2.4801 - val_accuracy: 0.3911\n",
      "Epoch 3/15\n",
      "915/915 [==============================] - 12s 14ms/step - loss: 2.4436 - accuracy: 0.3219 - val_loss: 2.0700 - val_accuracy: 0.5069\n",
      "Epoch 4/15\n",
      "915/915 [==============================] - 12s 13ms/step - loss: 2.0915 - accuracy: 0.4358 - val_loss: 1.7276 - val_accuracy: 0.6062\n",
      "Epoch 5/15\n",
      "915/915 [==============================] - 16s 17ms/step - loss: 1.8102 - accuracy: 0.5162 - val_loss: 1.4724 - val_accuracy: 0.6652\n",
      "Epoch 6/15\n",
      "915/915 [==============================] - 15s 17ms/step - loss: 1.6118 - accuracy: 0.5669 - val_loss: 1.2957 - val_accuracy: 0.7035\n",
      "Epoch 7/15\n",
      "915/915 [==============================] - 12s 14ms/step - loss: 1.4583 - accuracy: 0.6106 - val_loss: 1.1700 - val_accuracy: 0.7342\n",
      "Epoch 8/15\n",
      "915/915 [==============================] - 12s 13ms/step - loss: 1.3620 - accuracy: 0.6418 - val_loss: 1.0753 - val_accuracy: 0.7548\n",
      "Epoch 9/15\n",
      "915/915 [==============================] - 12s 13ms/step - loss: 1.2680 - accuracy: 0.6660 - val_loss: 0.9876 - val_accuracy: 0.7710\n",
      "Epoch 10/15\n",
      "915/915 [==============================] - 11s 12ms/step - loss: 1.1860 - accuracy: 0.6834 - val_loss: 0.9160 - val_accuracy: 0.7910\n",
      "Epoch 11/15\n",
      "915/915 [==============================] - 14s 15ms/step - loss: 1.1304 - accuracy: 0.7009 - val_loss: 0.8711 - val_accuracy: 0.7948\n",
      "Epoch 12/15\n",
      "915/915 [==============================] - 28s 30ms/step - loss: 1.0663 - accuracy: 0.7182 - val_loss: 0.8837 - val_accuracy: 0.7911\n",
      "Epoch 13/15\n",
      "915/915 [==============================] - 15s 16ms/step - loss: 1.0226 - accuracy: 0.7294 - val_loss: 0.7916 - val_accuracy: 0.8098\n",
      "Epoch 14/15\n",
      "915/915 [==============================] - 15s 17ms/step - loss: 0.9874 - accuracy: 0.7379 - val_loss: 0.7513 - val_accuracy: 0.8174\n",
      "Epoch 15/15\n",
      "915/915 [==============================] - 15s 16ms/step - loss: 0.9348 - accuracy: 0.7513 - val_loss: 0.7095 - val_accuracy: 0.8253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x25b9a5318b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tf_keras as keras\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "def create_esp32_simple_cnn():\n",
    "    inputs = keras.Input(shape=(64, 64, 1))\n",
    "    \n",
    "    x = keras.layers.Conv2D(16, (3, 3), strides=(2, 2), padding='same', activation='relu')(inputs)\n",
    "    \n",
    "    x = keras.layers.SeparableConv2D(32, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)\n",
    "    \n",
    "    x = keras.layers.SeparableConv2D(64, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)\n",
    "    \n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    \n",
    "    outputs = keras.layers.Dense(36, activation='softmax')(x)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "base_model = create_esp32_simple_cnn()\n",
    "\n",
    "q_aware_model = tfmot.quantization.keras.quantize_model(base_model)\n",
    "\n",
    "q_aware_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Iniciando Treinamento com QAT...\")\n",
    "q_aware_model.fit(train_ds, validation_data=val_ds, epochs=15) #parei aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f0e43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\paulo\\AppData\\Local\\Temp\\tmpjyz2ik46\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\paulo\\AppData\\Local\\Temp\\tmpjyz2ik46\\assets\n",
      "C:\\Users\\paulo\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\lite\\python\\convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo convertido com sucesso para modelo_placa_int8.tflite!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def representative_data_gen():\n",
    "    for input_value, _ in val_ds.take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "tflite_model_quant = converter.convert()\n",
    "\n",
    "with open(\"modelo_placa_int8.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model_quant)\n",
    "\n",
    "print(\"Modelo convertido com sucesso para modelo_placa_int8.tflite!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf2b23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo modelo_placa_int8.h gerado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def bin_to_header(filename, var_name='modelo_placa_int8'):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = f.read()\n",
    "    \n",
    "    with open(var_name + '.h', 'w') as f:\n",
    "        f.write(f'unsigned char {var_name}[] = {{\\n  ')\n",
    "        for i, byte in enumerate(data):\n",
    "            f.write(f'0x{byte:02x}, ')\n",
    "            if (i + 1) % 12 == 0:\n",
    "                f.write('\\n  ')\n",
    "        f.write('\\n};\\n\\n')\n",
    "        f.write(f'unsigned int {var_name}_len = {len(data)};\\n')\n",
    "\n",
    "bin_to_header('modelo_placa_int8.tflite')\n",
    "print(\"Arquivo modelo_placa_int8.h gerado com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
